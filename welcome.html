<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="keywords" content="Rui Zhao, Rui Zhao, 赵瑞, EE, USTC, CUHK, The Chinese University of Hong Kong, University of Science and Technology of China" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="rui.ico">
<title>Rui Zhao's Homepage</title>
</head>
<body>
<div id="layout-content">
<p>

<script type="text/javascript">
<!--
// Toggle Display of BibTeX
function toggleBibtex(articleid) {
  var bib = document.getElementById(articleid);
  // Toggle 
    if(bib.style.display == "none") {
      bib.style.display = "";
    }
    else {
      bib.style.display = "none";
    }
}
-->
</script>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-40926388-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

</p>

<p>
</p>
<table class="imgtable"><tr><td>
<img src="rui@sydney.jpg" alt="alt text" width="260px" height="HEIGHTpx" /> &nbsp;</td>
<td align="left">

<div id="toptitle"> 
  <h1>
  <a href="http://www.ee.cuhk.edu.hk/~rzhao/">Rui Zhao</a> &nbsp; 趙瑞
  </h1>
</div>

<p>
Ph.D. Candidate, supervised by <a href="http://www.ee.cuhk.edu.hk/~xgwang/">Prof. Xiaogang Wang</a>

<br />
<br />



Tel.(office): (852)3943-8253 <br />

Email: <a href="mailto:rzhao@ee.cuhk.edu.hk">rzhao at ee.cuhk.edu.hk</a><br />

Rm 304, Ho Sin Hang Engineering Building <br />

The Chinese University of Hong Kong, ShaTin, N.T., Hong Kong
</p>
</td></tr></table>

<h2>News</h2>
<ul>
<li>
  <p>
      Nov. 21, 2013: I am awarded travel grant to ICCV 2013!
  </p>
</li>
<li>
  <p>
    May 22, 2013: Project page of our CVPR'13 work is built, and source code of <a href="https://github.com/Robert0812/dense_feat">dense_feat</a> and <a href="https://github.com/Robert0812/salience_reid">salience_reid</a> are released. 
  </p>
</li>
<li>
  <p>May 15, 2013: Project page of salience for person re-identification is coming soon. 
  </p>
</li>
<li>
  <p>May 15, 2013: New homepage launched!
  </p>
</li>

</ul>
<h2>
  Biography 
</h2>
<ul>

<li>
  <p>
    I am a third-year Ph.D. student in <a href="http://www.ee.cuhk.edu.hk/">Department of Electronic Engineering</a> of <a href="http://www.cuhk.edu.hk/english/index.html">The Chinese University of Hong Kong (CUHK)</a>. Our group closely collaborates with <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Lab</a> supervised by <a href="http://www.ie.cuhk.edu.hk/people/xotang.shtml">Prof. Xiaoou Tang</a>. 
  </p>
</li>

<li>
  <p>
    I obtained the Bachelor degree in <a href="http://eeis.ustc.edu.cn/">Department of Electronic Engineering and Information Science (EEIS)</a> from <a href="http://en.ustc.edu.cn/"> University of Science and Technology of China (USTC)</a> in June 2010, and I completed my undergraduate thesis in <a href="http://www.ipc.ustc.edu.cn/index2.htm">Information Processing Center (IPC)</a>, supervised by <a href="http://staff.ustc.edu.cn/~ynh/">Prof. Nenghai Yu</a>. 
  </p>
</li>

<li>
  <p>
    My research interests include pattern recognition, machine learning, and particularly object matching and tracking in video surveillance, e.g. person re-identification, and vehicle counting.  
  </p>
</li>
</ul>

<h2>Journals</h2>
<ol>
<li>
<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6478825">Counting Vehicles from Semantic Regions, </a> <br />
<b>R. Zhao</b> and X. Wang. <br />
<i>IEEE Transactions on Intelligent Transportation Systems</i> (<b>T-ITS</b>). (Impact factor: 3.452) <br />
</li>
[<a href="papers/zhaoWtits13.pdf">PDF</a>]
[<a href="javascript:toggleBibtex('zhaoWtits13_abstract')" target="_self">Abstract</a>]
[<a href="javascript:toggleBibtex('zhaoWtits13')" target="_self">Bibtex</a>] 
[<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6478825">DOI</a>]

<div class="blockcontent" id="zhaoWtits13_abstract" style="display:none"> 
  <table class="imgtable">
    <tr>
      <td><a href="papers/zhaoWtits13.pdf"><img src="papers/zhaoWtits13.jpg" alt="alt text" width="200px" height="HEIGHTpx"/></a></td>
      <td><p>
          Automatically counting vehicles in complex trafﬁc scenes from videos is challenging. Detection and tracking algorithms may fail due to occlusions, scene clutters, and large variations of viewpoints and vehicle types. We propose a new approach of counting vehicles through exploiting contextual regularities from scene structures. It breaks the problem into simpler problems, which count vehicles on each path separately. The model of each path and its source and sink add strong regularization on the motion and the sizes of vehicles and can thus signiﬁcantly improve the accuracy of vehicle counting. Our approach is based on tracking and clustering feature points and can be summarized in threefold. First, an algorithm is proposed to automatically learn the models of scene structures. A trafﬁc scene is segmented into local semantic regions by exploiting the temporal cooccurrence of local motions. Local semantic regions are connected into global complete paths using the proposed fast marching algorithm. Sources and sinks are estimated from the models of semantic regions. Second, an algorithm is proposed to cluster trajectories of feature points into objects and to estimate average vehicle sizes at different locations from initial clustering results. Third, trajectories of features points are often fragmented due to occlusions. By integrating the spatiotemporal features of trajectory clusters with contextual models of paths and sources and sinks, trajectory clusters are assigned into different paths and connected into complete trajectories. Experimental results on a complex trafﬁc scene show the effectiveness of our approach.
      </p></td>
    </tr>
  </table>
</div>

<div class="blockcontent" id="zhaoWtits13" style="display:none"> 
<pre>
@inproceedings{zhao2013counting,
 title = {Counting Vehicles from Semantic Regions},
 author={Zhao, Rui and Wang, Xiaogang},
 booktitle = {IEEE Transaction on Intelligent Transportation Systems (T-ITS)},
 year = {2013}
}
</pre>
</div>

</ol>

<h2>Refereed Conference</h2>

<ol>

<li>
<a href="papers/zhaoOWiccv13.pdf">Person Re-identification by Salience Matching, </a> <br />
<b>R. Zhao</b>, W. Ouyang and X. Wang. <br />
<i>IEEE International Conference on Computer Vision</i> (<b>ICCV</b>), 2013. (Acceptance rate: 27.5%)<br />
</li>
[<a href="papers/zhaoOWiccv13.pdf">PDF</a>]
[<a href="javascript:toggleBibtex('zhaoOWiccv13_abstract')" target="_self">Abstract</a>]
[<a href="javascript:toggleBibtex('zhaoOWiccv13')" target="_self">Bibtex</a>]
[<a href="">Project Page</a>]
[<a href="papers/zhaoOWiccv13_poster.pdf">Poster</a>]
[<a href="codedata/iccv13/cmc_iccv13.tar.gz">CMC</a>]
<font color="red">~ new!</font>
<div class="blockcontent" id="zhaoOWiccv13_abstract" style="display:none"> 
  <table class="imgtable">
    <tr>
      <td><a href="papers/zhaoOWiccv13.jpg"><img src="papers/zhaoOWiccv13.jpg" alt="alt text" width="200px" height="HEIGHTpx"/></a></td>
      <td><p>
          Human salience is distinctive and reliable information in matching pedestrians across disjoint camera views. In this paper, we exploit the pairwise salience distribution relationship between pedestrian images, and solve the person re-identification problem by proposing a salience matching strategy. To handle the misalignment problem in pedestrian images, patch matching is adopted and patch salience is estimated. Matching patches with inconsistent salience brings penalty. Images of the same person are recognized by minimizing thesalience matching cost. Furthermore, our salience matching is tightly integrated with patch matching in a unified structural RankSVM learning framework. The effectiveness of our approach is validated on the VIPeR dataset and the CUHK Campus dataset. It outperforms the state-of-the-art methods on both datasets.
      </p></td>
    </tr>
  </table>
</div>

<!-- 
Human salience is distinctive and reliable information in matching pedestrians across disjoint camera views. In this paper, we exploit the pairwise salience distribution relationship between pedestrian images, and solve the person re-identification problem by proposing a salience matching strategy. To handle the misalignment problem in pedestrian images, patch matching is adopted and patch salience is estimated. Matching patches with inconsistent salience brings penalty. Images of the same person are recognized by minimizing thesalience matching cost. Furthermore, our salience matching is tightly integrated with patch matching in a unified structural RankSVM learning framework. The effectiveness of our approach is validated on the VIPeR dataset and the CUHK Campus dataset. It outperforms the state-of-the-art methods on both datasets.
 -->

<div class="blockcontent" id="zhaoOWiccv13" style="display:none"> 
<pre>
@inproceedings{zhao2013person,
 title = {Person Re-identification by Salience Matching},
 author={Zhao, Rui and Ouyang, Wanli and Wang, Xiaogang},
 booktitle = {IEEE International Conference on Computer Vision (ICCV)},
 year = {2013},
 month = {December},
 address = {Sydney, Australia}
}
</pre>
</div>

<br /><br />

<li>
<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6619304">Unsupervised Salience Learning for Person Re-identification, </a> <br />
<b>R. Zhao</b>, W. Ouyang and X. Wang. <br />
<i>IEEE International Conference on Computer Vision and Pattern Recognition </i> (<b>CVPR</b>), 2013. (Acceptance rate: 25.2%)<br />
</li>
[<a href="papers/zhaoOWcvpr13.pdf">PDF</a>]
[<a href="javascript:toggleBibtex('zhaoOWcvpr13_abstract')" target="_self">Abstract</a>]
[<a href="javascript:toggleBibtex('zhaoOWcvpr13')" target="_self">Bibtex</a>]
[<a href="http://mmlab.ie.cuhk.edu.hk/projects/project_salience_reid/index.html">Project Page</a>]
[<a href="papers/zhaoOWcvpr13_poster.pdf">Poster</a>]
[<a href= https://github.com/Robert0812/salience_reid>Code</a>]
[<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6619304">DOI</a>]
<div class="blockcontent" id="zhaoOWcvpr13_abstract" style="display:none"> 
  <table class="imgtable">
    <tr>
      <td><a href="papers/zhaoOWcvpr13.png"><img src="papers/zhaoOWcvpr13.png" alt="alt text" width="200px" height="HEIGHTpx"/></a></td>
      <td><p>
          Human eyes can recognize person identities based on some small salient regions. However, such valuable salient information is often hidden when computing similarities of images with existing approaches. Moreover, many existing approaches learn discriminative features and handle drastic viewpoint change in a supervised way and require labeling new training data for a different pair of camera views. In this paper, we propose a novel perspective for person re-identiﬁcation based on unsupervised salience learning. Distinctive features are extracted without requiring identity labels in the training procedure. First, we apply adjacency constrained patch matching to build dense correspondence between image pairs, which shows effectiveness in handling misalignment caused by large viewpoint and pose variations. Second, we learn human salience in an unsupervised manner. To improve the performance of person re-identiﬁcation, human salience is incorporated in patch matching to ﬁnd reliable and discriminative matched patches. The effectiveness of our approach is validated on the widely used VIPeR dataset and ETHZ dataset.
      </p></td>
    </tr>
  </table>
</div>

<div class="blockcontent" id="zhaoOWcvpr13" style="display:none"> 
<pre>
@inproceedings{zhao2013unsupervised,
 title = {Unsupervised Salience Learning for Person Re-identification},
 author={Zhao, Rui and Ouyang, Wanli and Wang, Xiaogang},
 booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 year = {2013},
 month = {June},
 address = {Portland, USA}
}
</pre>
</div>
<br /><br />

<li>
<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-37331-2_3">Human Reidentification with Transferred Metric Learning, </a> <br />
W. Li, <b>R. Zhao</b>, and X. Wang. <br />
<i>IEEE Asian Conference on Computer Vision </i> (<b>ACCV</b>), 2012. (Oral Acceptance rate: 3.6%) <br />
</li>
[<a href="papers/liZWaccv12.pdf">PDF</a>]
[<a href="javascript:toggleBibtex('liZWaccv12_abstract')" target="_self">Abstract</a>] 
[<a href="javascript:toggleBibtex('liZWaccv12')" target="_self">Bibtex</a>] 
[<a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html">Dataset</a>]
[<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-37331-2_3">DOI</a>]

<div class="blockcontent" id="liZWaccv12_abstract" style="display:none"> 
  <table class="imgtable">
    <tr>
      <td><a href="papers/liZWaccv12.jpg"><img src="papers/liZWaccv12.jpg" alt="alt text" width="200px" height="HEIGHTpx"/></a></td>
      <td><p>
          Human reidentification is to match persons observed in nonoverlapping camera views with visual features for inter-camera tracking. The ambiguity increases with the number of candidates to be distinguished. Simple temporal reasoning can simplify the problem by pruning the candidate set to be matched. Existing approaches adopt a fixed metric for matching all the subjects. Our approach is motivated by the insight that different visual metrics should be optimally learned for different candidate sets. We tackle this problem under a transfer learning framework. Given a large training set, the training samples are selected and reweighted according to their visual similarities with the query sample and its candidate set. A weighted maximum margin metric is online learned and transferred from a generic metric to a candidate-set-specific metric. The whole online reweighting and learning process takes less than two seconds per candidate set. Experiments on the VIPeR dataset and our dataset show that the proposed transferred metric learning significantly outperforms directly matching visual features or using a single generic metric learned from the whole training set.
      </p></td>
    </tr>
  </table>
</div>

<div class="blockcontent" id="liZWaccv12" style="display:none"> 
<pre>
@inproceedings{li2012human,
  title = {Human Reidentification with Transferred Metric Learning},
  author={Li, Wei and Zhao, Rui and Wang, Xiaogang},
  booktitle = {Proceedings of Asian Conference on Computer Vision (ACCV)},
  year = {2012}
}
</pre>
</div>
<br /><br />

<li>
<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5651004">SVD Based Linear Filtering in DCT Domain, </a> <br />
L. Zhuang, <b>R. Zhao</b>, N. Yu and B. Liu. <br />
<i>IEEE International Conference on Image Processing </i> (<b>ICIP</b>), 2010. <br />
</li>
[<a href="papers/zhuangZicip10.pdf">PDF</a>]
[<a href="javascript:toggleBibtex('zhuangZicip10_abstract')" target="_self">Abstract</a>] 
[<a href="javascript:toggleBibtex('zhuangZicip10')" target="_self">Bibtex</a>] 
[<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5651004">DOI</a>]

<div class="blockcontent" id="zhuangZicip10_abstract" style="display:none"> 
  <table class="imgtable">
    <tr>
      <td><a href="papers/zhuangZicip10.jpg"><img src="papers/zhuangZicip10.jpg" alt="alt text" width="200px" height="HEIGHTpx"/></a></td>
      <td><p>
          Efficient linear filtering in DCT domain is important in the area of processing and manipulation of image and video streams compressed in DCT-based method. In this paper, we proposed a novel method for linear filtering in DCT domain, regardless of filter type. We decompose any filter by SVD into weighted separable sub-filters which are well studied. Then we do fast linear filtering using these separable subfilters in DCT domain, and combine their results. To our best knowledge, it is the first method capable to do linear filtering with any type of filters directly in DCT domain. The scheme is demonstrated and discussed by doing Gabor filtering in DCT domain. Experiment results show that convolution result using the proposed solution is the same as that in spatial domain. Furthermore, our scheme is well suitable for distributed computing, which will improve computing speed greatly.
      </p></td>
    </tr>
  </table>
</div>

<div class="blockcontent" id="zhuangZicip10" style="display:none"> 
<pre>
@inproceedings{zhuang2010SVD,
 title = {SVD Based Linear Filtering in DCT Domain},
 author={Zhuang Liansheng and Zhao, Rui and Yu, Nenghai and Liu, Bin},
 booktitle = {IEEE International Conference on Image Processing (ICIP)},
 year = {2010}
}
</pre>
</div>
</ol>




<h2>
  Teaching
</h2>

Teaching assistant at CUHK for the following courses:
<ul>
<li><p>2011-2012, Fall &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Basic Circuit Theory (ENGG1110A). <br />
</p>
</li>
<li><p>2011-2012, Spring &nbsp;&nbsp;&nbsp;&nbsp; Introduction to Engineering Design (ENGG1100). <br />
</p>
</li>
<li><p>2012-2013, Fall &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Basic Circuit Theory (ENGG1110B). <br />
</p>
</li>
<li><p>2012-2013, Spring &nbsp;&nbsp;&nbsp;&nbsp; Problem Solving By Java Programming (ENGG1110D). <br />
</p>
</li>
<li>
<p>
2013-2014, Spring &nbsp;&nbsp;&nbsp;&nbsp; Problem Solving By Java Programming (ENGG1110J). <br />
</p>
</li>

<li>
  <p>
  2013-2014, Spring &nbsp;&nbsp;&nbsp;&nbsp; <a href="https://github.com/Robert0812/Tutorial_PR">Pattern Recognition (ENGG5202)</a>. <br />
  </p>
</li>

</ul>

<h2>Softwares</h2>
<ul>
<li>
  <p>
    <a href="https://github.com/Robert0812/dense_feat">dense_feat</a> : MATLAB package of dense color histogram and SIFT feature extraction.
    </p>
</li>
<li>
  <p>
    <a href="https://github.com/Robert0812/salience_reid">salience_reid</a> : MATLAB package of unsupervised salience learning for person re-identification.
  </p>
</li>
</ul>

<h2>Links
</h2>

<p>
  <a href="http://www.cuhk.edu.hk/english/index.html"><img src="figures/cuhk.jpg" alt="alt text" width="70px" height="HEIGHTpx"/></a>

  <a href="http://en.ustc.edu.cn/"><img src="figures/ustc.jpg" alt="alt text" width="50px" height="50px"/></a>

  <a href="http://bashu.cn/"><img src="figures/bashu.jpg" alt="alt text" width="50px" height="50px"/></a>

  <a title="View LinkedIn Profile" href="http://www.linkedin.com/pub/rui-zhao/27/70a/323"><img src='http://www.kaggle.com/content/v/6ea9cdfb5cbc/shared/img/profile-linkedin.png' width="30px" /></a>

  <a title="View Github Profile" href="https://github.com/Robert0812"><img src='http://www.kaggle.com/content/v/300688b9fb13/shared/img/profile-github.png' width="30px" /></a>
  
</p>

<div id="footer">
<div id="footer-text">
<strong>Hi, you are the 
<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=8960957; 
var sc_invisible=0; 
var sc_security="7339caeb"; 
var sc_text=2; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="hits counter"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="http://c.statcounter.com/8960957/0/7339caeb/0/"
alt="hits counter"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
-th visitor since 2013-05-15.</strong> </br>Last updated at 2013-12-10 by Rui Zhao. Page created using <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</div>


</body>
</html>
